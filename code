"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"i-T3CxUTVLvO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759206615082,"user_tz":-330,"elapsed":5232,"user":{"displayName":"Ishita Sahu","userId":"01573889057616199026"}},"outputId":"65d18d75-8038-4e7b-fba1-5c54042832a4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","\n","folder_path = '/content/drive/MyDrive/Mini_google'\n","\n","# Step 1: Get the list of files\n","files = os.listdir(folder_path)\n","print(f\"Total files: {len(files)}\")\n","\n","# Step 2: Read each file into a dictionary\n","texts = {}\n","for file_name in files:\n","    file_path = os.path.join(folder_path, file_name)\n","    with open(file_path, 'r', encoding='utf-8') as f:\n","        texts[file_name] = f.read()\n","\n","print(f\"Loaded {len(texts)} files successfully!\")\n"],"metadata":{"id":"txZdnzn3ebLL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759206615096,"user_tz":-330,"elapsed":12,"user":{"displayName":"Ishita Sahu","userId":"01573889057616199026"}},"outputId":"45152b76-b8e9-4365-c555-437bae19347f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Total files: 30\n","Loaded 30 files successfully!\n"]}]},{"cell_type":"code","source":["import re\n","\n","def preprocess(text):\n","    # remove [1], [23], etc.\n","    text = re.sub(r'\\[\\d+\\]', '', text)\n","\n","    # lowercase + remove punctuation/special chars\n","    text = re.sub(r'[^a-z0-9\\s]', ' ', text.lower())\n","\n","    # split into words\n","    words = text.split()\n","\n","    # remove stopwords\n","    stopwords = {\"the\", \"is\", \"was\", \"and\", \"of\", \"in\", \"to\", \"on\", \"for\",\"a\",\"s\", \"with\",\"as\"}\n","    words = [w for w in words if w not in stopwords]\n","\n","    return words\n"],"metadata":{"id":"Wex1CLAnBX6T","executionInfo":{"status":"ok","timestamp":1759206615099,"user_tz":-330,"elapsed":1,"user":{"displayName":"Ishita Sahu","userId":"01573889057616199026"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from collections import defaultdict\n","\n","def build_inverted_index(file_contents):\n","    inverted_index = defaultdict(dict)  # word -> {file: freq}\n","\n","    for file_name, text in file_contents.items():\n","        words = preprocess(text)\n","        for word in words:\n","            inverted_index[word][file_name] = inverted_index[word].get(file_name, 0) + 1\n","\n","    return inverted_index\n"],"metadata":{"id":"eu4YbqhxBaEd","executionInfo":{"status":"ok","timestamp":1759206615147,"user_tz":-330,"elapsed":46,"user":{"displayName":"Ishita Sahu","userId":"01573889057616199026"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def search(word, inverted_index):\n","    word = word.lower()\n","    if word in inverted_index:\n","        results = inverted_index[word]\n","        sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n","        return sorted_results\n","    else:\n","        return None\n"],"metadata":{"id":"A8IBzuX4BhLW","executionInfo":{"status":"ok","timestamp":1759206615150,"user_tz":-330,"elapsed":1,"user":{"displayName":"Ishita Sahu","userId":"01573889057616199026"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def multi_word_search(query, inverted_index, mode=\"AND\"):\n","    words = preprocess(query)  # clean + tokenize the query\n","\n","    if not words:\n","        return []\n","\n","    # Get posting lists for each word\n","    posting_lists = []\n","    for word in words:\n","        if word in inverted_index:\n","            posting_lists.append(set(inverted_index[word].keys()))\n","        else:\n","            posting_lists.append(set())  # word not found\n","\n","    if mode == \"AND\":\n","        result_files = set.intersection(*posting_lists) if posting_lists else set()\n","    elif mode == \"OR\":\n","        result_files = set.union(*posting_lists) if posting_lists else set()\n","    else:\n","        raise ValueError(\"Mode must be 'AND' or 'OR'\")\n","\n","    # Collect frequencies (sum for OR, min for AND)\n","    results = {}\n","    for file in result_files:\n","        if mode == \"AND\":\n","            results[file] = min(inverted_index[w][file] for w in words if file in inverted_index[w])\n","        else:  # OR\n","            results[file] = sum(inverted_index[w].get(file, 0) for w in words)\n","\n","    # Sort by frequency (descending)\n","    sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n","    return sorted_results\n"],"metadata":{"id":"okVQanSdBkMi","executionInfo":{"status":"ok","timestamp":1759206615153,"user_tz":-330,"elapsed":1,"user":{"displayName":"Ishita Sahu","userId":"01573889057616199026"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def pretty_print_results(results, query):\n","    if not results:\n","        print(f\"No exact matches found for '{query}'\")\n","        return\n","\n","    print(f\"\\nSearch results for '{query}':\")\n","    for rank, (file, score) in enumerate(results, start=1):\n","        print(f\"{rank}. {file}  (score: {score})\")\n"],"metadata":{"id":"mJ0JOrXsCGQq","executionInfo":{"status":"ok","timestamp":1759206615236,"user_tz":-330,"elapsed":1,"user":{"displayName":"Ishita Sahu","userId":"01573889057616199026"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def levenshtein(a, b):\n","    n, m = len(a), len(b)\n","    if n > m:\n","        a, b = b, a\n","        n, m = m, n\n","\n","    current = range(n+1)\n","    for i in range(1, m+1):\n","        previous, current = current, [i] + [0]*n\n","        for j in range(1, n+1):\n","            insert_cost = previous[j] + 1\n","            delete_cost = current[j-1] + 1\n","            replace_cost = previous[j-1] + (a[j-1] != b[i-1])\n","            current[j] = min(insert_cost, delete_cost, replace_cost)\n","    return current[n]\n"],"metadata":{"id":"QnaSioi7CQ4m","executionInfo":{"status":"ok","timestamp":1759206615244,"user_tz":-330,"elapsed":4,"user":{"displayName":"Ishita Sahu","userId":"01573889057616199026"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def suggest_word(word, inverted_index, max_distance=2):\n","    candidates = []\n","    for vocab_word in inverted_index.keys():\n","        distance = levenshtein(word, vocab_word)\n","        if distance <= max_distance:\n","            candidates.append((vocab_word, distance))\n","    candidates.sort(key=lambda x: x[1])  # closest first\n","    return [w for w, d in candidates[:3]]  # top 3 suggestions\n"],"metadata":{"id":"LxV4L1Q-CVgU","executionInfo":{"status":"ok","timestamp":1759206615292,"user_tz":-330,"elapsed":50,"user":{"displayName":"Ishita Sahu","userId":"01573889057616199026"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from collections import Counter\n","\n","def build_doc_vectors(file_contents):\n","    doc_vectors = {}\n","    for file_name, text in file_contents.items():\n","        words = preprocess(text)\n","        doc_vectors[file_name] = Counter(words)\n","    return doc_vectors\n"],"metadata":{"id":"E_kLUblfCd6U","executionInfo":{"status":"ok","timestamp":1759206615297,"user_tz":-330,"elapsed":3,"user":{"displayName":"Ishita Sahu","userId":"01573889057616199026"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["doc_vectors = build_doc_vectors(texts)\n","\n","file_to_check = \"Virat.txt\"   # change to any file you want to verify\n","\n","if file_to_check in doc_vectors:\n","    print(f\"Vector successfully created for {file_to_check}\")\n","    vector = doc_vectors[file_to_check]\n","    print(f\"Total unique words in {file_to_check}: {len(vector)}\")\n","\n","    # show top 15 words by frequency\n","    print(\"\\nTop 15 words in this file:\")\n","    for word, freq in vector.most_common(15):\n","        print(f\"{word}: {freq}\")\n","else:\n","    print(f\"{file_to_check} not found in doc_vectors\")\n"],"metadata":{"id":"ThvhDDLSyqeJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759206615308,"user_tz":-330,"elapsed":12,"user":{"displayName":"Ishita Sahu","userId":"01573889057616199026"}},"outputId":"dc481e50-c4a9-4f31-d6b2-6fdd3e0cb1b9"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Vector successfully created for Virat.txt\n","Total unique words in Virat.txt: 468\n","\n","Top 15 words in this file:\n","kohli: 30\n","his: 29\n","he: 28\n","runs: 22\n","team: 18\n","against: 17\n","match: 13\n","under: 12\n","cricket: 11\n","india: 11\n","19: 11\n","delhi: 9\n","at: 9\n","first: 9\n","an: 9\n"]}]},{"cell_type":"code","source":["import math\n","\n","def cosine_similarity(query_vector, doc_vector):\n","    # dot product\n","    dot = sum(query_vector[w] * doc_vector.get(w, 0) for w in query_vector)\n","\n","    # norms\n","    query_norm = math.sqrt(sum(v**2 for v in query_vector.values()))\n","    doc_norm = math.sqrt(sum(v**2 for v in doc_vector.values()))\n","\n","    if query_norm == 0 or doc_norm == 0:\n","        return 0.0\n","    return dot / (query_norm * doc_norm)\n"],"metadata":{"id":"fkC8p57SCfRT","executionInfo":{"status":"ok","timestamp":1759206615330,"user_tz":-330,"elapsed":10,"user":{"displayName":"Ishita Sahu","userId":"01573889057616199026"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def rank_documents(query, inverted_index, doc_vectors, top_n=5):\n","    words = preprocess(query)\n","    query_vector = Counter(words)\n","\n","    # Build a vocabulary from all unique words in the inverted index\n","    vocabulary = set(inverted_index.keys())\n","\n","    scores = {}\n","    for file, doc_vector in doc_vectors.items():\n","        # Create a vector for the document using the full vocabulary\n","        full_doc_vector = {word: doc_vector.get(word, 0) for word in vocabulary}\n","\n","        # Create a vector for the query using the full vocabulary\n","        full_query_vector = {word: query_vector.get(word, 0) for word in vocabulary}\n","\n","        score = cosine_similarity(full_query_vector, full_doc_vector)\n","        if score > 0:\n","            scores[file] = score\n","\n","    # sort by similarity score\n","    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n","    return ranked[:top_n]"],"metadata":{"id":"uwmUXsiCCjnp","executionInfo":{"status":"ok","timestamp":1759206615333,"user_tz":-330,"elapsed":1,"user":{"displayName":"Ishita Sahu","userId":"01573889057616199026"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["inverted_index = build_inverted_index(texts)\n","print(f\"Total unique words in index: {len(inverted_index)}\")\n","\n","# pick a sample word to test\n","test_word = \"india\"\n","\n","if test_word in inverted_index:\n","    print(f\"\\nWord '{test_word}' found in {len(inverted_index[test_word])} file(s):\")\n","    for file, freq in inverted_index[test_word].items():\n","        print(f\"  {file} : {freq}\")\n","else:\n","    print(f\"\\nWord '{test_word}' not found in index\")\n"],"metadata":{"id":"lrv5_-ZbyFZl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759206615557,"user_tz":-330,"elapsed":222,"user":{"displayName":"Ishita Sahu","userId":"01573889057616199026"}},"outputId":"d205eb73-d23f-4204-b054-1b52b1e03419"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Total unique words in index: 5259\n","\n","Word 'india' found in 4 file(s):\n","  Gandhi.txt : 5\n","  Cricket.txt : 1\n","  Virat.txt : 11\n","  Shiva.txt : 2\n"]}]},{"cell_type":"code","source":["!pip install gradio==3.50.2"],"metadata":{"id":"NqREV2NW20Xd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759206625245,"user_tz":-330,"elapsed":9686,"user":{"displayName":"Ishita Sahu","userId":"01573889057616199026"}},"outputId":"383ddcf6-3026-4e5b-a723-6a7422e5b90f"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gradio==3.50.2 in /usr/local/lib/python3.12/dist-packages (3.50.2)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (23.2.1)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (5.5.0)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.116.2)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.6.1)\n","Requirement already satisfied: gradio-client==0.6.1 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.6.1)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.28.1)\n","Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.35.0)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (6.5.2)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (3.1.6)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (2.1.5)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (3.10.0)\n","Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (1.26.4)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (3.11.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (25.0)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (2.2.2)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (10.4.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (2.11.9)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.25.1)\n","Requirement already satisfied: python-multipart in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.0.20)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (6.0.2)\n","Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (2.32.4)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (2.10.0)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (4.15.0)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.35.0)\n","Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (11.0.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==0.6.1->gradio==3.50.2) (2025.3.0)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2) (4.25.1)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2) (2.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (3.19.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (4.67.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (1.1.10)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (4.60.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (1.4.9)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (3.2.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio==3.50.2) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio==3.50.2) (2025.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (0.4.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests~=2.0->gradio==3.50.2) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests~=2.0->gradio==3.50.2) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests~=2.0->gradio==3.50.2) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests~=2.0->gradio==3.50.2) (2025.8.3)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.14.0->gradio==3.50.2) (8.2.1)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.14.0->gradio==3.50.2) (0.16.0)\n","Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi->gradio==3.50.2) (0.48.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->gradio==3.50.2) (4.10.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->gradio==3.50.2) (1.0.9)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (2025.9.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (0.27.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==3.50.2) (1.17.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->gradio==3.50.2) (1.3.1)\n"]}]},{"cell_type":"code","source":["import gradio as gr\n","\n","# --- UI CALLBACKS ---\n","def ui_single_word(query):\n","    if not query.strip():\n","        return \"<p>Please enter a word.</p>\"\n","    res = search(query, inverted_index)\n","    if res:\n","        out = f\"<h3>Results for '{query}'</h3><ul>\"\n","        for file, score in res:\n","            out += f\"<li><b>{file}</b> : {score}</li>\"\n","        out += \"</ul>\"\n","        return out\n","    sug = suggest_word(query, inverted_index)\n","    if sug:\n","        return f\"<p>No results for '{query}'. Did you mean: <b>{', '.join(sug)}</b>?</p>\"\n","    return f\"<p>No results for '{query}'</p>\"\n","\n","def ui_multi_word(query, mode):\n","    if not query.strip():\n","        return f\"<p>Please enter words for {mode} search.</p>\"\n","    res = multi_word_search(query, inverted_index, mode=mode)\n","    if res:\n","        out = f\"<h3>{mode} Search Results for '{query}'</h3><ul>\"\n","        for file, score in res:\n","            out += f\"<li><b>{file}</b> : {score}</li>\"\n","        out += \"</ul>\"\n","        return out\n","    return f\"<p>No {mode} results for '{query}'</p>\"\n","\n","def ui_recommend(query):\n","    if not query.strip():\n","        return \"<p>Please enter a query.</p>\"\n","    res = rank_documents(query, inverted_index, doc_vectors, top_n=5)  # fixed top 5\n","    if res:\n","        out = f\"<h3>Recommended files for '{query}'</h3><ul>\"\n","        for file, score in res:\n","            out += f\"<li><b>{file}</b> : {score:.4f}</li>\"\n","        out += \"</ul>\"\n","        return out\n","    return f\"<p>No recommendations for '{query}'</p>\"\n","\n","def ui_show_vector(filename, topn):\n","    if not filename.strip():\n","        return \"<p>Please enter a filename.</p>\"\n","    if filename not in doc_vectors:\n","        return f\"<p>File <b>{filename}</b> not found.</p>\"\n","    vec = doc_vectors[filename].most_common(int(topn))\n","    out = f\"<h3>Top {topn} words in {filename}</h3><ul>\"\n","    for word, freq in vec:\n","        out += f\"<li>{word}: {freq}</li>\"\n","    out += \"</ul>\"\n","    return out\n","\n","# --- GRADIO APP ---\n","with gr.Blocks(css=\"body { font-family: Arial; margin:20px;} h3 {color:#2c3e50;}\") as demo:\n","    gr.Markdown(\"# Mini Google Search Engine (Web Interface)\")\n","\n","    # --- Single Word Search ---\n","    with gr.Tab(\"Single Word Search\"):\n","        q1 = gr.Textbox(label=\"Enter word\", placeholder=\"e.g., computer\")\n","        out1 = gr.HTML()\n","        q1.submit(ui_single_word, q1, out1)\n","        gr.Button(\"Search\").click(ui_single_word, q1, out1)\n","\n","    # --- Multi-word Search ---\n","    with gr.Tab(\"Multi-word Search\"):\n","        q2 = gr.Textbox(label=\"Enter words\", placeholder=\"e.g., computer science\")\n","        mode = gr.Radio([\"AND\", \"OR\"], value=\"AND\", label=\"Mode\", interactive=True)\n","        out2 = gr.HTML()\n","        q2.submit(ui_multi_word, [q2, mode], out2)\n","        gr.Button(\"Search\").click(ui_multi_word, [q2, mode], out2)\n","        mode.change(ui_multi_word, [q2, mode], out2)\n","\n","    # --- File Recommendation (Top 5 fixed) ---\n","    with gr.Tab(\"File Recommendation\"):\n","        q3 = gr.Textbox(label=\"Enter query\", placeholder=\"e.g., cricket batting captain\")\n","        out3 = gr.HTML()\n","        q3.submit(ui_recommend, q3, out3)\n","        gr.Button(\"Recommend\").click(ui_recommend, q3, out3)\n","\n","    # --- File Vector ---\n","    with gr.Tab(\"File Vector\"):\n","        filename = gr.Textbox(label=\"Enter filename (e.g., Virat.txt)\")\n","        topv = gr.Slider(5, 50, value=15, step=1, label=\"Top words\")\n","        out4 = gr.HTML()\n","        filename.submit(ui_show_vector, [filename, topv], out4)\n","        gr.Button(\"Show Vector\").click(ui_show_vector, [filename, topv], out4)\n","        topv.release(ui_show_vector, [filename, topv], out4)\n","\n","# Launch the app\n","demo.launch()\n","\n","\n"],"metadata":{"id":"dNdRXrQS3gA9","colab":{"base_uri":"https://localhost:8080/","height":660},"executionInfo":{"status":"ok","timestamp":1759206638815,"user_tz":-330,"elapsed":13565,"user":{"displayName":"Ishita Sahu","userId":"01573889057616199026"}},"outputId":"fab6d18b-48b2-4dcf-e9a3-194e41ceb32a"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n","--------\n","Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Running on public URL: https://67dda5523f15c1015b.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://67dda5523f15c1015b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" 
frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":16}]}]}
